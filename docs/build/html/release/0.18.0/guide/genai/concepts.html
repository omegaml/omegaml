

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Concepts in omega-ml Generative AI &mdash; omega-ml 0.18.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=9edc463e" />
      <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=7ca4e891" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=ba2e7b09"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Tutorial for Generative AI" href="tutorial.html" />
    <link rel="prev" title="Generative AI" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            omega-ml
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../quickstart/index.html">Introduction</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">User Guide</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../intro/index.html">Getting started</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html">Generative AI</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Concepts in omega-ml Generative AI</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#generative-ai-model">Generative AI model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#model-provider">Model Provider</a></li>
<li class="toctree-l4"><a class="reference internal" href="#pipelines-and-guardrails">Pipelines and Guardrails</a></li>
<li class="toctree-l4"><a class="reference internal" href="#documents-storage">Documents storage</a></li>
<li class="toctree-l4"><a class="reference internal" href="#conversation-history">Conversation history</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tools">Tools</a></li>
<li class="toctree-l4"><a class="reference internal" href="#generative-ai-runtime-and-rest-services">Generative AI runtime and REST services</a></li>
<li class="toctree-l4"><a class="reference internal" href="#multi-model-repository">Multi-model Repository</a></li>
<li class="toctree-l4"><a class="reference internal" href="#oci-repository-model-deployments">OCI Repository Model Deployments</a></li>
<li class="toctree-l4"><a class="reference internal" href="#monitoring">Monitoring</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="tutorial.html">Tutorial for Generative AI</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../classicml/index.html">Classic ML</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pipelines/index.html">Task Automation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../clusters/index.html">Deployment and Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cli/index.html">Command-line interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="../advanced/index.html">Advanced features</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../admin/index.html">Deploying omega-ml</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../devguide/index.html">Extending omega-ml</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/index.html">Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../support.html">Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/index.html">Changes</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">omega-ml</a>
      </nav>

      <div class="wy-nav-content">


        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">User Guide</a></li>
          <li class="breadcrumb-item"><a href="index.html">Generative AI</a></li>
      <li class="breadcrumb-item active">Concepts in omega-ml Generative AI</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/guide/genai/concepts.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="concepts-in-omega-ml-generative-ai">
<h1>Concepts in omega-ml Generative AI<a class="headerlink" href="#concepts-in-omega-ml-generative-ai" title="Link to this heading">¶</a></h1>
<p>omega-ml’s promise is to deliver complex AI workflows with minimal code. This is
achieved by providing a set of components that can be easily combined to create
powerful AI applications. The components are designed to be modular and reusable,
allowing users to mix and match according to requirements.</p>
<nav class="contents local" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#generative-ai-model" id="id1">Generative AI model</a></p></li>
<li><p><a class="reference internal" href="#model-provider" id="id2">Model Provider</a></p></li>
<li><p><a class="reference internal" href="#pipelines-and-guardrails" id="id3">Pipelines and Guardrails</a></p></li>
<li><p><a class="reference internal" href="#documents-storage" id="id4">Documents storage</a></p></li>
<li><p><a class="reference internal" href="#conversation-history" id="id5">Conversation history</a></p></li>
<li><p><a class="reference internal" href="#tools" id="id6">Tools</a></p></li>
<li><p><a class="reference internal" href="#generative-ai-runtime-and-rest-services" id="id7">Generative AI runtime and REST services</a></p></li>
<li><p><a class="reference internal" href="#multi-model-repository" id="id8">Multi-model Repository</a></p></li>
<li><p><a class="reference internal" href="#oci-repository-model-deployments" id="id9">OCI Repository Model Deployments</a></p></li>
<li><p><a class="reference internal" href="#monitoring" id="id10">Monitoring</a></p></li>
</ul>
</nav>
<section id="generative-ai-model">
<h2><a class="toc-backref" href="#id1" role="doc-backlink">Generative AI model</a><a class="headerlink" href="#generative-ai-model" title="Link to this heading">¶</a></h2>
<p>A generative AI model is a type of AI model that can generate new content based on
a given input, also known as a prompt. In omega-ml we can define a generative model
by specifying the URL to a model provider, the model name, and the model type (embedding model,
text or multi-modal model), and give these specifications a name to store in the model
repository.</p>
<p>While models can be used for generation of content or responses to user input, other models
are used to create embeddings. Embeddings are numerical representations of data that can be used
to compare and retrieve similar data. For example, a text embedding model can convert
a piece of text into a numeric representation (a vector), which can then be used to find similar
pieces of text.</p>
<p>In omega-ml both types of models are defined in the same way, namely by specifying the URL
to a model provider, the model name, and the model type.</p>
</section>
<section id="model-provider">
<h2><a class="toc-backref" href="#id2" role="doc-backlink">Model Provider</a><a class="headerlink" href="#model-provider" title="Link to this heading">¶</a></h2>
<p>A model provider is a service that hosts and serves AI models. omega-ml
provides a transparent interface to various model providers, allowing users to easily switch
between them without changing their code. This enables users to leverage the best models
available for their specific use cases. Currently omega-ml supports the following model providers
out of the box:</p>
<p><em>Open Source</em></p>
<ul class="simple">
<li><p>vLLM - a high-performance, open-source model serving framework that supports
multiple backends, including Hugging Face and OpenAI models. vLLM is designed for
low-latency and high-throughput inference, making it ideal for real-time applications.</p></li>
<li><p>LocalAI - a local model serving framework that allows users to run models on their own
hardware. LocalAI is designed for users who want to have full control over their
models and data, and it supports a wide range of models, including those from
Hugging Face and OpenAI.</p></li>
<li><p>AnythingLLM - a local model serving framework that allows users to run models on their own
hardware. AnythingLLM is designed for users who want to have full control over their
models and data, and it supports a wide range of models, including those from
Hugging Face and OpenAI.</p></li>
<li><p>GPT4All - a local model serving framework that allows users to run models on their own
hardware. GPT4All is designed for users who want to have full control over their
models and data, and it supports a wide range of models, including those from
Hugging Face and OpenAI.</p></li>
</ul>
<p><em>Commercial</em></p>
<ul class="simple">
<li><p>OpenAI - a commercial model provider that offers a wide range of models for various
tasks, including text generation, image generation, and more. OpenAI is known for its
high-quality models and ease of use.</p></li>
<li><p>OpenRouter - a commercial model provider that offers a wide range of models for various
tasks, including text generation, image generation, and more. OpenRouter is known for
its high-quality models and ease of use.</p></li>
<li><p>Infomaniak - a Swiss commercial model provider that offers a wide range of models for various
tasks, including text generation, image generation, and more. Infomaniak is known for
its high-quality models and ease of use with Swiss Hosting.</p></li>
<li><p>Any provider offering a OpenAI-compatible set of APIs, specifically /completions,
/chat/completions and /embeddings.</p></li>
</ul>
</section>
<section id="pipelines-and-guardrails">
<h2><a class="toc-backref" href="#id3" role="doc-backlink">Pipelines and Guardrails</a><a class="headerlink" href="#pipelines-and-guardrails" title="Link to this heading">¶</a></h2>
<p>Every generative AI model in omega-ml is part of a pipeline, a sequence of steps
that are executed in order to process some part of the completion process. For example, the
steps include prompt preprocessing, model inference, and postprocessing. Each step in the pipeline
can adjust the input to the model, how the model is called, and process or modify the output
after inference.</p>
<p>A pipeline in omega-ml is simply a callable object attached to a model, that takes inputs and
returns an output. For example, the pipeline implement guardrails (content or security checks)
by checking the input and output to the model, and modifying it if necessary.</p>
</section>
<section id="documents-storage">
<h2><a class="toc-backref" href="#id4" role="doc-backlink">Documents storage</a><a class="headerlink" href="#documents-storage" title="Link to this heading">¶</a></h2>
<p>Document storage is a key component of generative AI workflows, as it allows users to
store and retrieve documents which provide additional context to a model when completing a
user’s input. Similarly to other transparent data access in omega-ml, we can define a
a document storage by providing the URL to a supported database, and storing this definition
in the dataset repository.</p>
<p>For a document storage to be useful, we also need an embedding model, which is a type of
a generative AI model that can convert documents into embeddings. These embeddings are then
stored in the document storage, allowing for efficient retrieval and comparison of documents.</p>
</section>
<section id="conversation-history">
<h2><a class="toc-backref" href="#id5" role="doc-backlink">Conversation history</a><a class="headerlink" href="#conversation-history" title="Link to this heading">¶</a></h2>
<p>Conversation history is a key component of generative AI workflows, as it allows users
to store and retrieve the history of a conversation with a model. This is useful for
maintaining context and providing a more coherent experience for the user.</p>
<p>In omega-ml, conversation history is automatically stored in its database, and and can be
retrieved and used to inform the model’s responses. This is particularly useful for chatbots
and other conversational agents, where maintaining context is crucial for providing relevant
responses across a longer conversation.</p>
</section>
<section id="tools">
<h2><a class="toc-backref" href="#id6" role="doc-backlink">Tools</a><a class="headerlink" href="#tools" title="Link to this heading">¶</a></h2>
<p>Tools are a key component of generative AI workflows, as they allow users to extend the
functionality of their models and pipelines. A tool is some external functionality that
can be provided to a model, such as a database lookup, a custom function to calculate
a result, or a call to an external API. Tools can be used to augment the capabilities of a model,
whereby the model can call the tool to perform some action, and then use the result of that action
to inform its response to the user.</p>
<p>In omega-ml, tools are defined as a callable object that can be attached to a model and can
be called by the model during inference. Tool calls are processed as part of the pipeline in
order to modify the input to the tool, replace the tool call, or modify its output.</p>
</section>
<section id="generative-ai-runtime-and-rest-services">
<h2><a class="toc-backref" href="#id7" role="doc-backlink">Generative AI runtime and REST services</a><a class="headerlink" href="#generative-ai-runtime-and-rest-services" title="Link to this heading">¶</a></h2>
<p>omegaml provides a customizable runtime to meet the specific resource and distribution
requirements of generative AI models. For example, in a corporate environment the runtime
can be configured to use a local model provider, such as vLLM or LocalAI, to ensure that
data is not sent to a third-party provider. The runtime can also be configured to use
autoscaling for scalability and high availability, and to automatically distribute
inference requests across multiple nodes.</p>
</section>
<section id="multi-model-repository">
<h2><a class="toc-backref" href="#id8" role="doc-backlink">Multi-model Repository</a><a class="headerlink" href="#multi-model-repository" title="Link to this heading">¶</a></h2>
<p>It is often useful to configure multiple models, templates and pipelines to implement
different use case scenarios. For example, one generative AI model can be configured to
answer questions about a company’s products, while another model can be configured to
provide guidances on human resources policies.</p>
<p>In omega-ml we can define multiple models, templates and pipelines in a single repository,
and then use these models in different workflows. This allows users to easily switch
between different models and pipelines, and to reuse them in different workflows.</p>
</section>
<section id="oci-repository-model-deployments">
<h2><a class="toc-backref" href="#id9" role="doc-backlink">OCI Repository Model Deployments</a><a class="headerlink" href="#oci-repository-model-deployments" title="Link to this heading">¶</a></h2>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 0.18.0.</span></p>
</div>
<p>AI models tend to be several GB in size, requiring specialized storage. OCI repositories, also
known as container/docker image repositories, are a perfect match. They have been built to
support arbitrary storage sizes efficiently and serve as a backbone for deployment to clusters.</p>
<p>omega-ml’s model store provides transparent support for storing any model into a OCI repository.
This enables AI teams to use the same simplified approach to deploying customized AI models that
omega-ml provides for ML models, namely by saving the model to the omega-ml model store and using
the omega-ml runtime for training and inference. omega-ml transparently handles the storage,
distribution and runtime loading using a registered OCI repository.</p>
</section>
<section id="monitoring">
<h2><a class="toc-backref" href="#id10" role="doc-backlink">Monitoring</a><a class="headerlink" href="#monitoring" title="Link to this heading">¶</a></h2>
<p>omega-ml provides a built-in model tracking and monitoring system. This works the same
way for all models, including generative AI models. The tracking system automatically logs
all interactions with a model, including the input, output, and any metadata associated with the
interaction. All interactions are stored to the model repository for later query and analysis.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Generative AI" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="tutorial.html" class="btn btn-neutral float-right" title="Tutorial for Generative AI" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025 (c) omegaml.io by one2seven GmbH.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>

      </div>
    </section>
  </div>
  <!-- version plugin for rtd template without sidebar -->
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"> Other Versions</span>
    v: release/0.18.0
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Tags</dt>
      <dd><a href="../../../../0.11.3/index.html" class="version-ref-0.11.3">0.11.3</a></dd>
      <dd><a href="../../../../0.11.4/index.html" class="version-ref-0.11.4">0.11.4</a></dd>
      <dd><a href="../../../../0.12.0/index.html" class="version-ref-0.12.0">0.12.0</a></dd>
      <dd><a href="../../../../0.13.0/index.html" class="version-ref-0.13.0">0.13.0</a></dd>
      <dd><a href="../../../../0.13.2/index.html" class="version-ref-0.13.2">0.13.2</a></dd>
      <dd><a href="../../../../0.13.4/index.html" class="version-ref-0.13.4">0.13.4</a></dd>
      <dd><a href="../../../../0.13.5/index.html" class="version-ref-0.13.5">0.13.5</a></dd>
      <dd><a href="../../../../0.13.6/index.html" class="version-ref-0.13.6">0.13.6</a></dd>
      <dd><a href="../../../../0.13.7/index.html" class="version-ref-0.13.7">0.13.7</a></dd>
      <dd><a href="../../../../0.14.0/index.html" class="version-ref-0.14.0">0.14.0</a></dd>
      <dd><a href="../../../../0.15.1/index.html" class="version-ref-0.15.1">0.15.1</a></dd>
      <dd><a href="../../../../0.15.2/index.html" class="version-ref-0.15.2">0.15.2</a></dd>
      <dd><a href="../../../../latest/guide/genai/concepts.html" class="version-ref-latest">latest</a></dd>
      <dd><a href="../../../0.15.3/index.html" class="version-ref-release/0.15.3">0.15.3</a></dd>
      <dd><a href="../../../0.15.5/index.html" class="version-ref-release/0.15.5">0.15.5</a></dd>
      <dd><a href="../../../0.16.0/index.html" class="version-ref-release/0.16.0">0.16.0</a></dd>
      <dd><a href="../../../0.16.1/index.html" class="version-ref-release/0.16.1">0.16.1</a></dd>
      <dd><a href="../../../0.16.2/index.html" class="version-ref-release/0.16.2">0.16.2</a></dd>
      <dd><a href="../../../0.16.3/index.html" class="version-ref-release/0.16.3">0.16.3</a></dd>
      <dd><a href="../../../0.16.4/index.html" class="version-ref-release/0.16.4">0.16.4</a></dd>
      <dd><a href="../../../0.17.0/guide/genai/concepts.html" class="version-ref-release/0.17.0">0.17.0</a></dd>
      <dd><a href="concepts.html" class="version-ref-release/0.18.0">0.18.0</a></dd>
      <dd><a href="../../../0.4/index.html" class="version-ref-release/0.4">0.4</a></dd>
      <dd><a href="../../../0.5/index.html" class="version-ref-release/0.5">0.5</a></dd>
      <dd><a href="../../../0.9/index.html" class="version-ref-release/0.9">0.9</a></dd>
      <dd><a href="../../../../stable/guide/genai/concepts.html" class="version-ref-stable">stable</a></dd>
    </dl>
    <dl>
      <dt>Branches</dt>
      <dd><a href="../../../../master/guide/genai/concepts.html">master</a></dd>
    </dl>
  </div>
</div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>